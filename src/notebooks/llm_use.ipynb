{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "import re\n",
    "\n",
    "# Настройки модели\n",
    "llm_name = \"qwen2:72b-instruct-q4_0\"\n",
    "num_ctx = 8192\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=llm_name,\n",
    "    temperature=0,\n",
    "    num_ctx=num_ctx,\n",
    ").with_retry(\n",
    "    retry_if_exception_type=(ValueError, TimeoutError),\n",
    "    wait_exponential_jitter=True,\n",
    "    stop_after_attempt=3,\n",
    ")\n",
    "class DataExtractionSchema(BaseModel):\n",
    "    response_class: str = Field()\n",
    "    need_more_info: str = Field()\n",
    "    model_response: str = Field()\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    response_class: str\n",
    "    need_more_info: str\n",
    "    model_response: str\n",
    "\n",
    "system_message = \"\"\"\\\n",
    "Для того чтобы модель возвращала ответы в формате JSON с классификацией по классам и указанием, нужна ли дополнительная информация, можно разработать следующий промпт. Этот промпт будет позволять модели анализировать ответы клиентов и структурировать выходные данные по заданным классам, добавляя флаги необходимости дополнительной информации.\n",
    "\n",
    "### Пример промпта:\n",
    "\n",
    "```markdown\n",
    "<system_prompt>\n",
    "YOU ARE A CUSTOMER RESPONSE CLASSIFICATION AGENT. YOUR TASK IS TO ANALYZE CLIENT RESPONSES AND CATEGORIZE THEM INTO PREDEFINED CLASSES. EACH CLIENT RESPONSE SHOULD BE MAPPED TO ONE OF THE FIVE RESPONSE CLASSES (1, 3, 4, OR 5), AND FOR EACH RESPONSE, YOU SHOULD ALSO IDENTIFY IF ADDITIONAL INFORMATION IS NEEDED FROM THE CLIENT. YOUR OUTPUT SHOULD BE IN JSON FORMAT AND INCLUDE THE FOLLOWING FIELDS:\n",
    "\n",
    "1. \"response_class\": (integer) — THE CLASS OF THE RESPONSE (1, 3, 4, 5).\n",
    "2. \"need_more_info\": (boolean) — TRUE IF ADDITIONAL INFORMATION IS REQUIRED FROM THE CLIENT, OTHERWISE FALSE.\n",
    "3. \"model_response\": (string) — THE APPROPRIATE RESPONSE TO THE CLIENT BASED ON THE PROVIDED EXAMPLES.\n",
    " \n",
    "### Chain of Thoughts:\n",
    "\n",
    "1. **Analyzing the Response**: \n",
    "   1.1. Identify the client's intent and determine the class (1, 3, 4, 5).\n",
    "   1.2. Based on the class, evaluate if further information or clarification is needed (for example, if the client mentions another party or if the client’s response is unclear).\n",
    "   \n",
    "2. **Composing the Response**: \n",
    "   2.1. Craft a response that fits the context of the client's message, mirroring the examples provided.\n",
    "   2.2. Make sure the response is clear, polite, and professional.\n",
    "   \n",
    "3. **Formatting the Output**: \n",
    "   3.1. Output the final response in JSON format with all necessary fields filled.\n",
    "\n",
    "### Example Input:\n",
    "\n",
    "Client response: \"Добрый день! Нет потребности.\"\n",
    "\n",
    "### Expected JSON Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"response_class\": \"1\",\n",
    "  \"need_more_info\": \"false\",\n",
    "  \"model_response\": \"[Имя клиента], Благодарим вас за обратную связь! Мы всегда стремимся улучшать наш продукт, чтобы соответствовать ожиданиям наших клиентов. В случае, если ваша потребность изменится, мы будем рады помочь. Вы всегда можете ознакомиться с нашей услугой по [ссылке] и связаться с нами в удобное для вас время. С уважением, Команда Napoleon IT. Отзывы\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Example Client Responses with Output:\n",
    "\n",
    "#### Example 1:\n",
    "Client response: \"Привет, да посмотрели. Есть сотрудники, которые тестировали ваш сервис в компании Зарина. Пользы не принесло. Нам вполне хватает мп статс и чат жпт.\"\n",
    "\n",
    "Expected JSON Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"response_class\": \"1\",\n",
    "  \"need_more_info\": \"false\",\n",
    "  \"model_response\": \"[Имя клиента], Спасибо за ваш отклик! Мы всегда стремимся внедрять новейшие технологии, которые помогают бизнесам решать задачи максимально эффективно. Наш продукт, «Napoleon IT отзывы», позволяет не только сократить время на обработку обратной связи, но и повысить лояльность и удовлетворенность клиентов за счет глубокой аналитики и автоматизации процессов. Мы понимаем, что у вас уже есть внутренние решения, однако будем рады вновь обсудить наши возможности, если вы решите дополнить свои инструменты или оптимизировать текущие процессы. С уважением, Команда Napoleon IT. Отзывы\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Example 2:\n",
    "Client response: \"Супер! Мы сейчас в огне пытаемся успеть вовремя открыть новый дом бренда. Напишите в октябре.\"\n",
    "\n",
    "Expected JSON Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"response_class\": \"3\",\n",
    "  \"need_more_info\": \"false\",\n",
    "  \"model_response\": \"Понял вас. Желаю удачи с открытием нового дома бренда. Вернёмся к вам в октябре. С уважением, Команда Napoleon IT. Отзывы\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Example 3:\n",
    "Client response: \"Добрый день :) Напишите ваше предложение на info@tseh85.ru, коллеги посмотрят)\"\n",
    "\n",
    "Expected JSON Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"response_class\": \"4\",\n",
    "  \"need_more_info\": \"false\",\n",
    "  \"model_response\": \"Спасибо за ваш ответ! Мы обязательно направим наше предложение на указанный адрес info@tseh85.ru для рассмотрения коллегами. Будем рады сотрудничеству! С уважением, Команда Napoleon IT. Отзывы\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Example 4:\n",
    "Client response: \"Роман, добрый день! Я нахожусь в отпуске до 16 сентября, можем запланировать демо после этой даты?\"\n",
    "\n",
    "Expected JSON Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"response_class\": \"5\",\n",
    "  \"need_more_info\": \"false\",\n",
    "  \"model_response\": \"Отлично, договорились. Мы можем запланировать демо после 16 сентября. Я передал ваши контакты нашему агенту, и он свяжется с вами в ближайшее время для согласования деталей. Также отправляю вам краткую презентацию для ознакомления. Хорошего отдыха! С уважением, Команда Napoleon IT. Отзывы\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### Example 5:\n",
    "Client response: \"Вы могли бы написать ваше предложение на почту и я направлю это коллегам?\"\n",
    "\n",
    "Expected JSON Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"response_class\": \"4\",\n",
    "  \"need_more_info\": \"true\",\n",
    "  \"model_response\": \"Да, конечно! Отправим предложение на почту. Можете тогда прислать контакты коллег, чтобы обсудить детали напрямую? Будем рады сотрудничеству!\"\n",
    "}\n",
    "```\n",
    "\n",
    "### What Not To Do:\n",
    "\n",
    "- **NEVER FAIL TO RETURN OUTPUT IN JSON FORMAT.**\n",
    "- **DO NOT CLASSIFY RESPONSES INCORRECTLY. PAY CLOSE ATTENTION TO CONTEXT.**\n",
    "- **DO NOT FORGET TO SET THE \"NEED_MORE_INFO\" FLAG TO TRUE IF ADDITIONAL DETAILS ARE REQUIRED.**\n",
    "- **AVOID PROVIDING RESPONSES THAT LACK POLITENESS OR PROFESSIONALISM.**\n",
    "</system_prompt>\n",
    "```\n",
    "\n",
    "### Объяснение:\n",
    "1. **Цепочка рассуждений** четко ведет модель по этапам анализа ответа клиента и генерации правильного ответа.\n",
    "2. **JSON формат** позволяет структурировать данные для дальнейшей обработки, включая флаги для дополнительных запросов.\n",
    "3. Примерные клиентские ответы используются для демонстрации правильного формата и структуры.\n",
    "\n",
    "\n",
    "Output schema:\n",
    "{OutputSchema.schema()}\n",
    "\"\"\"\n",
    "\n",
    "# Шаблон для запроса к модели\n",
    "template = \"\"\"\\\n",
    "Документ:\n",
    "{input}\\\n",
    "\"\"\"\n",
    "\n",
    "final_prompt_template = PromptTemplate.from_template(template)\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessagePromptTemplate(prompt=final_prompt_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Создаем цепочку\n",
    "chain = chat_prompt_template | llm | JsonOutputParser()\n",
    "\n",
    "def extract_information(text: str) -> dict:\n",
    "    try:\n",
    "        result = chain.invoke({\"input\": text})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обработке: {e}\")\n",
    "        return {\"Ошибка\": \"Не удалось обработать запрос\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_class': '5',\n",
       " 'need_more_info': 'true',\n",
       " 'model_response': 'Конечно, мы можем перенести звонок. Пожалуйста, уточните более удобное для вас время или дату.'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_information(\"Можем созвонится на позже\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
